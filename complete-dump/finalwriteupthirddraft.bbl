\begin{thebibliography}{18}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Baxter et~al.(1998)Baxter, Trigdell, and Weaver]{baxter98knightcap}
Jonathan Baxter, Andrew Trigdell, and Lex Weaver.
\newblock Knightcap: a chess program that learns by combining {TD}($\lambda$)
  with game-tree search.
\newblock In \emph{Proc. 15th International Conf. on Machine Learning}, pages
  28--36. Morgan Kaufmann, San Francisco, CA, 1998.
\newblock URL \url{http://citeseer.ist.psu.edu/baxter98knightcap.html}.

\bibitem[Bdolah and Livnat(2000)]{yaeltetris}
Yael Bdolah and Dror Livnat.
\newblock Reinforcement learning playing tetris.
\newblock 2000.
\newblock URL
  \url{http://www.math.tau.ac.il/~mansour/rl-course/student\_proj/livnat/tetri%
s.html}.

\bibitem[Boyan and Littman(1994)]{boyan94packet}
Justin~A. Boyan and Michael~L. Littman.
\newblock Packet routing in dynamically changing networks: {A} reinforcement
  learning approach.
\newblock In Jack~D. Cowan, Gerald Tesauro, and Joshua Alspector, editors,
  \emph{Advances in Neural Information Processing Systems}, volume~6, pages
  671--678. Morgan Kaufmann Publishers, Inc., 1994.
\newblock URL \url{http://citeseer.ist.psu.edu/boyan94packet.html}.

\bibitem[Breukelaar et~al.(2004)Breukelaar, Demaine, Hohenberger, Hoogeboom,
  Kosters, and Liben-Nowell]{hardtet}
Ron Breukelaar, Erik~D. Demaine, Susan Hohenberger, Hendrik~Jan Hoogeboom,
  Walter~A. Kosters, and David Liben-Nowell.
\newblock Tetris is hard, even to approximate.
\newblock \emph{International Journal of Computational Geometry \&
  Applications}, 14:1-2:\penalty0 41, 2004.
\newblock URL \url{http://theory.csail.mit.edu/~dln/papers/tetris/tetris.pdf}.

\bibitem[Brzustowski(1992)]{mathproof}
John Brzustowski.
\newblock Can you win at tetris?
\newblock Master's thesis, University of British Columbia, 1992.

\bibitem[Burgiel(1997)]{losetetris}
Heidi Burgiel.
\newblock How to lose at tetris.
\newblock \emph{Mathematical Gazette}, 81:491:\penalty0 194--200, 1997.
\newblock URL
  \url{http://www.findarticles.com/p/articles/mi\_qa3773/is\_199803/ai\_n87851%
30}.

\bibitem[Crites and Barto(1996)]{elevator}
R.~H. Crites and A.~G. Barto.
\newblock Improving elevator performance using reinforcement learning.
\newblock In D.~S. Touretzky, M.~C. Mozer, and M.~E. H., editors,
  \emph{Advances in Neural Information Processing Systems: Proceedings of the
  1995 Conference}, pages 1017--1023, Cambridge, MA, 1996. MIT Press.

\bibitem[Driessens(2004)]{kurt}
Kurt Driessens.
\newblock \emph{Relational Reinforcement Learning}.
\newblock PhD thesis, Catholic University of Leuven, 2004.
\newblock URL \url{http://www.cs.kuleuven.ac.be/~kurtd/PhD/}.

\bibitem[Fahey(2003)]{tetstand}
Colin~P. Fahey.
\newblock Tetris specifications \& world records, 2003.
\newblock URL
  \url{http://www.colinfahey.com/2003jan\_tetris/2003jan\_tetris.htm}.

\bibitem[Gamma et~al.(1998)Gamma, Helm, Johnson, and Vlissides]{designp}
Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides.
\newblock \emph{Design Patterns: Elements of Reusable Object-Oriented
  Software}.
\newblock Addison Wesley Longman, Inc., 1998.

\bibitem[Kaelbling et~al.(1996)Kaelbling, Littman, and
  Moore]{kaelbling96reinforcement}
Leslie~Pack Kaelbling, Michael~L. Littman, and Andrew~P. Moore.
\newblock Reinforcement learning: A survey.
\newblock \emph{Journal of Artificial Intelligence Research}, 4:\penalty0
  237--285, 1996.
\newblock URL \url{http://citeseer.ist.psu.edu/kaelbling96reinforcement.html}.

\bibitem[Kimura et~al.(1997)Kimura, Miyazaki, and Kobayashi]{rlrobotics}
H.~Kimura, K.~Miyazaki, and S.~Kobayashi.
\newblock Reinforcement learning in {POMDP}s with function approximation.
\newblock In \emph{Proc. 14th International Conf. on Machine Learning}, pages
  152--160. Morgan Kaufmann, San Francisco, CA, 1997.
\newblock URL \url{http://www.fe.dis.titech.ac.jp/~gen/robot/robodemo.html}.

\bibitem[McLean(2001)]{evvsrl}
Clinton~Brett McLean.
\newblock Design, evaluation and comparrison of evolution and reinforcement
  learning models.
\newblock Master's thesis, Rhodes University, 2001.

\bibitem[Melax(1998)]{melaxtetris}
Stan Melax.
\newblock Reinforcement learning tetris example.
\newblock 1998.
\newblock URL \url{http://www.melax.com/tetris/}.

\bibitem[Sutton and Barto(2002)]{suttonbarto}
Richard~S. Sutton and Andrew~G. Barto.
\newblock \emph{Reinforcement Learning: An Introduction}.
\newblock The MIT Press, Cambridge, MA, 2002.
\newblock URL \url{http://www.cs.ualberta.ca/sutton/book/ebook/index.html}.

\bibitem[Sutton et~al.(2005)Sutton, Kuhlmann, and Stone]{keepaway}
Richard~S. Sutton, Gregory Kuhlmann, and Peter Stone.
\newblock Reinforement learning for robocup-soccer keepaway, 2005.

\bibitem[Tesauro(1995)]{tdgammon}
Gerald Tesauro.
\newblock Temporal difference learning and td-gammon.
\newblock \emph{Communications of the ACM}, 38\penalty0 (3), 1995.
\newblock URL \url{http://www.research.ibm.com/massive/tdl.html}.

\bibitem[Thrun and Schwartz(1993)]{thrun93issues}
Sebastian Thrun and Anton Schwartz.
\newblock {Issues in Using Function Approximation for Reinforcement Learning}.
\newblock In M.~Mozer, P.~Smolensky, D.~Touretzky, J.~Elman, and A.~Weigend,
  editors, \emph{Proceedings of the 1993 Connectionist Models Summer School},
  Hillsdale, NJ, 1993. Lawrence Erlbaum.
\newblock URL \url{http://citeseer.ist.psu.edu/thrun93issues.html}.

\end{thebibliography}
